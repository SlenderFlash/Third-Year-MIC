{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmes de descente en optimisation différentiable sans contrainte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettez ci-dessous les imports classiques de librairie Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce TP, nous nous intéressons aux algorithmes pour la minimisation sans contrainte de fonctionnelles très générales: le problème s'écrit:\n",
    "\n",
    "$$\\min_{x\\in\\mathbb{R}^n} f(x).$$\n",
    "\n",
    "Le but de cette séance est l'écriture d'un code de minimisation locale, et l'évaluation de ses performances sur les fonctions tests suivantes:\n",
    "\n",
    "<li>$f_1(x,y) = 2(x+y-2)^2+(x-y)^2$.\n",
    "<li>$f_2(x,y) = 100(y-x^2)^2 + (1-x)^2$ (fonction de Rosenbrock).\n",
    "\n",
    "On appelle $\\textit{oracle}$ une routine qui à un $x$ donné, renvoie la valeur $f(x)$ du critère, le gradient $\\nabla f(x)$ (ou une approximation du gradient) s'il existe, et éventuellement la matrice Hessienne $H[f](x)$ (ou une approximation) si elle existe et si nécessaire:\n",
    "\n",
    "$$[f(x),\\nabla f(x),H[f](x)] = \\textrm{oracle}(x)$$\n",
    "\n",
    "> **A faire :** Calculer les gradients et les Hessiennes des deux fonctions proposées et implémenter les fonctions $\\textrm{oracle}$ correspondantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Réponse :** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle1(x):\n",
    "    return f,df,Hf\n",
    "\n",
    "def oracle2(x):\n",
    "    return f,df,Hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle qu'un algorithme de descente appliqué à la minimisation de $f$ possède la forme suivante:\n",
    "\n",
    "* **Données :** $x_0\\in \\mathbb{R}^n$ point initial arbitraire, un oracle.\n",
    "* **Initialisation :** Numéro d'itération: $k=0$.\n",
    "* **Tant que** le critère d'arrêt n'est pas satisfait, **faire**\n",
    "  * Calcul de la direction de descente $d_k$.\n",
    "  * Choix/Calcul du pas $s_k$.\n",
    "  * Mise à jour: calcul du prochain itéré $x_{k+1}$.\n",
    "  * $k = k + 1.$\n",
    "\n",
    "> **A faire :** Résolution mathématique:\n",
    "\n",
    "1. Donner les points critiques des fonctions proposées.\n",
    "2. Les fonctions $f_i$ admettent-elles des extrema sur $\\mathbb{R}^2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Réponse :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **A faire :** Implémenter deux algorithmes de mimimisation, un par méthode de gradient à pas fixe et l'autre par une méthode de Newton locale. Les arguments d'entrée sont `function` qui est l'oracle à minimiser, `xini` qui est le point initial et `h` qui est le pas de la méthode de gradient. Les arguments de sortie sont `x` la valeur finale du point trouvée, `xiter` qui est la valeur du point au cours des itérations et `nbiter` le nombre d'itérations pour arriver à convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient(function,h=1e-1,xini=np.array([0,0])):\n",
    "    return x,xiter,nbiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton(function,xini=[0,0]):\n",
    "    return x,xiter,nbiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **A faire :** En utilisant le module `matplotlib.pyplot`, on veut représenter/dessiner la suite des itérés dans $\\mathbb{R}^2$ avec la fonction `scatter`.On souhaite aussi représenter les fonctions $f_1$ et $f_2$ en utilisant la fonction `contour` du module `matplotlib.pyplot`. On s'inspirera du code qui suit pour créer deux fonctions (une pour chaque oracle) `affichage1(xiter)` et `affichage2(xiter)` qui affiche représente les itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx = 1000\n",
    "Ny = 1000\n",
    "x = np.linspace(-2,2,Nx)\n",
    "y = np.linspace(-2,2,Ny)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = 2*(X+Y-2)**2+(X-Y)**2\n",
    "CS=plt.contour(X, Y, Z,[0,0.1,1,2,4,6,8,12,16,20,24],colors='k')\n",
    "plt.clabel(CS, inline=1, fontsize=10)\n",
    "z = [[1,1.5],[0,0.5]]\n",
    "plt.scatter(z[0],z[1],marker='o')\n",
    "plt.show()\n",
    "\n",
    "def affichage1(xiter) :\n",
    "    pass\n",
    "def affichage2(xiter) :\n",
    "    pass\n",
    "affichage1(np.array(z))\n",
    "plt.show()\n",
    "affichage2(np.array(z))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **A faire :** Tester la méthode de Newton et la méthode de gradient pour différents points de départ et différents pas pour la fonction `oracle1` puis `oracle2`. Conclure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
